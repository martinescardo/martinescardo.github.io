\documentclass%
[%dvips,% for generating postscript printouts
%25pt,%
%a4paper,%
%landscape
Screen4to3,
%Screen16to9
]{foils}

\input{preamble}

\usepackage{amsmath,amssymb,url}

\newcommand{\myitem}[1]{\item[\darkblue{#1}]}

\title{\darkblue{What Sequential Games, the Tychonoff Theorem and the
  Double-Negation Shift have in Common}}

\author{\darkblue{Mart\'{\i}n Escard\'o}
\\ {University of Birmingham, UK} 
\\[10ex] Joint work with \darkblue{Paulo Oliva}, Queen Mary, London, UK. 
\\[1ex] ~}

\date{\sc MSFP 2010, Baltimore, 25th September 2010}

\begin{document}

\raggedright

\maketitle

%\setlength\textheight{\paperheight}
%\setlength\headheight{-7ex}
%\setlength\footskip{20ex}
%\addtolength\foilheadskip{-20ex}
%\addtolength\voffset{20ex}



\newcommand{\concat}{\operatorname{{+}{+}}}
\newcommand{\next}{\operatorname{next}}
\newcommand{\argsup}{\operatorname{argsup}}
%\newcommand{\R}{\mathbb{R}}


\overhead{Abstract}

%\vfill

I will discuss a higher-type functional, written here in Haskell,
which

\vfill

\noindent
\darkblue{(1)}~calculates \darkblue{optimal strategies} for sequential games, 

\vfill

\noindent
\darkblue{(2)}~implements a computational version of
  the \darkblue{Tychonoff Theorem} 
\\ ~~~~ from topology,  

\vfill

\noindent
\darkblue{(3)}~realizes the
  \darkblue{Double-Negation Shift} from logic and proof theory. 
%\\ ~~~~ from logic and proof theory. 

\vfill

\overhead{Abstract}

\vfill

This functional makes sense for both \darkblue{finite} and
\darkblue{infinite} lists.

\vfill

The \darkblue{binary} case amounts to an operation that is available in any monad,
specialized to a certain \darkblue{selection monad}.

\vfill

Once this monad is defined, this functional turns
out to be already available in the \darkblue{Haskell Standard Prelude}, called
\darkblue{$\mathtt{sequence}$}

\vfill

\overhead{An amazingly versatile functional} 

\begin{verbatim}
 bigotimes :: [(x -> r) -> x] -> ([x] -> r) -> [x]
 bigotimes [] p = []
 bigotimes (e : es) p = x0 : bigotimes es (p.(x0:))
   where x0 = e(\x -> p(x : bigotimes es (p.(x:))))
\end{verbatim}

\vfill

\grey{1.}~\darkblue{$\mathtt{r}$} is a type of \darkblue{generalized truth values}.

\grey{2.}~\darkblue{$(\mathtt{x} \to \mathtt{r}) \to \mathtt{x}$} is a type of \darkblue{selection functions}.

\grey{3.}~The input is a list of selection functions for \darkblue{$\mathtt{x}$}.

  
\grey{4.}~The output is a single, combined selection function for \darkblue{$[\mathtt{x}]$}.

\overhead{Products of selection functions}


If the
input list of selection functions is
\[
\darkblue{\varepsilon = [\varepsilon_0,\varepsilon_1,\dots,\varepsilon_n,\dots]},
\]
then the mathematical notation for the output of the algorithm is 
\[
\darkblue{\bigotimes_i \varepsilon_i}.
\]
The definition of the algorithm amounts to a recursive definition,
\[
\darkblue{\bigotimes_i \varepsilon_i = \varepsilon_0 \otimes \bigotimes_i
\varepsilon_{i+1}},
\]
for a suitable binary operation \darkblue{$\otimes$} that combines two selection
functions. 

\overhead{What I intend to do in this talk}

\vfill

\grey{1.}~Explain the main ideas behind \darkblue{selection functions}x and
the mathematical operation~\darkblue{$\bigotimes$}.

\vfill

\grey{2.}~Implement some sample applications in functional
programming:
\\[2ex] \qquad\darkblue{1.}~playing \darkblue{Tic-Tac-Toe},
\\[2ex] \qquad\darkblue{2.}~solving the \darkblue{$n$-Queens} puzzle, and 
\\[2ex] \qquad\darkblue{3.}~deciding \darkblue{equality of functions} (!)
on certain infinite types.

\overhead{Organization} 

\grey{2.}~Selection functions. 

\grey{3.}~Products of selection functions. 

\grey{4.}~Playing games. 

\grey{5.}~The Tychonoff Theorem. 

\grey{6.}~Monads. 

\grey{7.}~The Double-Negation Shift. 

\vfill

Probably too much for a one-hour talk. We'll see how far we get.

\overhead{Selection functions} 

If we define
\begin{verbatim}
 type J r x = (x -> r) -> x 
\end{verbatim}
then the type specification of the function \verb+bigotimes+ can be
rewritten as
\begin{verbatim}
 bigotimes :: [J r x] -> J r [x]
\end{verbatim}

\vfill

The type \verb+J r+ turns out to have the structure of a (strong) monad.

We'll explore this towards the end of the talk.

\overhead{Quantifiers}

\vfill
To understand the type constructor \darkblue{$\mathtt{J}$}, we also consider
\begin{verbatim}
 type K r x = (x -> r) -> r
\end{verbatim}

\vfill

\darkblue{Continuation monad}, related to~\verb+call/cc+ and CPS
translation, classical logic.

\vfill

We regard it as a type of generalized \darkblue{quantifiers}
with \darkblue{truth values $\mathtt{r}$}. 

\vfill

With \darkblue{$\mathtt{r} = \mathtt{Bool}$}, two elements of the type
\darkblue{$\mathtt{K~r~x}$} are the \darkblue{existential} and
\darkblue{universal} quantifiers.


\overhead{Monad morphism from $\mathtt{J~r}$ to $\mathtt{K~r}$}


We'll use this morphism before we give \darkblue{$\mathtt{J~r}$} the
structure of a monad:
\begin{verbatim}
 overline :: J r x -> K r x
 overline e = \p -> p(e p)
\end{verbatim}

\vfill

The Haskell notation 
\[
\darkblue{\mathtt{overline~e}}
\]
corresponds to the mathematical notation 
\[
\darkblue{\overline
\varepsilon}. 
\]

This operation transforms \darkblue{selection functions} into
\darkblue{quantifiers}.

\overhead{Terminology}

\vfill

~~~~~~
  \begin{tabular}{|c|c|c|c|} \hline Terminology & Mathematics &
    Haskell & Type \\ \hline\hline predicate & $p,q$ & \verb+p+,
    \verb+q+ & \verb+x -> r+ \\ \hline selection function &
    $\varepsilon, \delta$ & \verb+e+, \verb+d+ &
    \verb+J r x = ((x -> r) -> x)+ 
\\ \hline quantifier & $\phi,
    \gamma$ & \verb+phi+, \verb+gamma+ &
    \verb+K r x = ((x -> r) -> r)+ 
\\ \hline
\end{tabular}

\vfill


\overhead{Selection functions for sets}

A selection function for a set finds an element for which a
given predicate holds. 
\[
\darkblue{\begin{cases}
  S \subseteq X & \\
  p \colon X \to \mathtt{Bool} & \\
  \varepsilon(p) \in S
\end{cases}}
\]

\vfill

\darkblue{1.}~We require our selection functions to be \darkblue{total}.


\darkblue{2.}~We select an arbitrary element of~\darkblue{$S$} if none
satisfies~\darkblue{$p$}.

\darkblue{3.}~This forces \darkblue{$S$} to be non-empty. 

\overhead{Haskell code}
\begin{verbatim}
 find :: [x] -> J Bool x
 find []     p = undefined
 find [x]    p = x
 find (x:xs) p = if p x then x else find xs p

 forsome, forevery :: [x] -> K Bool x
 forsome  = overline.find
 forevery xs p = not(forsome xs (not.p))
\end{verbatim}
Or, expanding the definitions,
\begin{verbatim}
 forsome xs p = p(find xs p)
\end{verbatim}

\overhead{Hilbert's $\varepsilon$-calculus}

Our definition of the existential quantifier is the same as in
Hilbert's \darkblue{$\varepsilon$}-calculus:
\[
\darkblue{\exists x \,\, p(x) \iff p(\varepsilon(p))}.
\]


\vfill

The definition of \darkblue{$\mathtt{forevery}$} uses the De Morgan Law
for quantifiers,
\[
\darkblue{\forall x\,\, p(x) \iff \neg \exists x \,\, \neg p(x)}.
\]

\overhead{E.g.}


\begin{verbatim}
 find    [1..100] (\x -> odd x && x > 17) = 19
 forsome [1..100] (\x -> odd x && x > 17) = True

 find    [1..100] (\x -> odd x && even x) = 100
 forsome [1..100] (\x -> odd x && even x) = False
\end{verbatim}


\vfill

As already discussed, we are interested in finite non-empty lists only,
to make sure the produced selection function is total. 


\overhead{Summary so far}

A selection function \darkblue{$\varepsilon$} for a set \darkblue{$S$}
has to satisfy:

\vfill

\begin{enumerate}
\item[\grey{1.}]~\darkblue{$\varepsilon(p) \in S$}, whether or not there actually is some \darkblue{$x \in S$} such that \darkblue{$p(x)$} holds. 
\item[\grey{2.}]~If \darkblue{$p(x)$} holds for some \darkblue{$x \in S$}, then it holds for \darkblue{$x=\varepsilon(p)$}. 
\end{enumerate}

\vfill

The first condition forces the set~\darkblue{$S$} to be non-empty.

\overhead{Haskell code}
We shall need this later:
\begin{verbatim}
 findBool :: J Bool Bool
 findBool p = p True
\end{verbatim}

\vfill

This is equivalent to
\begin{verbatim}
 findBool p = if p True then True else False
\end{verbatim}

\overhead{Selection functions for quantifiers}

If \darkblue{$\phi(p)$} stands for \darkblue{$\exists x \in S\,\, p(x)$}, then Hilbert's
condition can be written as % an equation,

\[
\darkblue{\phi(p) = p(\varepsilon(p))},
\]

or equivalently, %using the monad morphism, as the equation
\[
\darkblue{\phi = \overline{\varepsilon}}.
\]

\darkgreen{If this equation holds, we say that \darkblue{$\varepsilon$} is a selection
function for the quantifier~\darkblue{$\phi$}.}

~

\grey{Thus, a selection function for a set \darkblue{$S$} is the same thing
as a selection function for the existential quantifier
of~\darkblue{$S$}.}

\overhead{Example: selection function for a universal quantifier}

When \darkblue{$\phi(p)$} is the universal quantifier
\darkblue{$\forall x \in S \ \ p(x)$} of the set~$S$, this amounts to
\begin{enumerate}
\item \darkblue{$\varepsilon(p) \in S$}.
\item If \darkblue{$p(x)$} holds for \darkblue{$x = \varepsilon(p)$},
  then it holds for all \darkblue{$x \in S$}.
\end{enumerate}

\vfill
\phantom{This is known as the \darkblue{Drinker Paradox}.}

\phantom{\darkgreen{In every pub there is a person \darkblue{$a$} such that if
  \darkblue{$a$} drinks then everybody drinks.}}

\phantom{Here \darkblue{$S$} is the set of people in the pub, and
\darkblue{$p(x)$} means that \darkblue{$x$} drinks, and we calculate
\darkblue{$a$} with the selection function as \darkblue{$a =
  \varepsilon(p)$}.}

\overhead{Example: selection function for a universal quantifier}

When \darkblue{$\phi(p)$} is the universal quantifier
\darkblue{$\forall x \in S \ \ p(x)$} of the set~$S$, this amounts to
\begin{enumerate}
\item \darkblue{$\varepsilon(p) \in S$}.
\item If \darkblue{$p(x)$} holds for \darkblue{$x = \varepsilon(p)$},
  then it holds for all \darkblue{$x \in S$}.
\end{enumerate}

\vfill
This is known as the \darkblue{Drinker Paradox}.

\darkgreen{In every pub there is a person \darkblue{$a$} such that if
  \darkblue{$a$} drinks then everybody drinks.}

Here \darkblue{$S$} is the set of people in the pub, and
\darkblue{$p(x)$} means that \darkblue{$x$} drinks, and we calculate
\darkblue{$a$} with the selection function as \darkblue{$a =
  \varepsilon(p)$}.


\overhead{Haskell code} 

A selection function for the universal quantifier of a finite set:
\begin{verbatim}
 findnot :: [x] -> J Bool x
 findnot []     p = undefined
 findnot [x]    p = x
 findnot (x:xs) p = if p x then findnot xs p else x
\end{verbatim}
This satisfies
\begin{verbatim}
 findnot xs p = find xs (not.p)
\end{verbatim}
and the function \verb+forevery+ defined earlier satisfies
\begin{verbatim}
 forevery = overline.findnot
\end{verbatim}

\overhead{Another useful instance of $\mathtt{r}$}

Consider ``predicates'' that give \darkblue{numbers} rather than
\darkblue{boolean} truth values.

\vfill

\darkblue{E.g.}, the  predicate may assign prices to goods. 

%Given such a predicate, we may wish to:
\begin{enumerate}
\item[\grey{1.}]
Find the \darkblue{price} of the most expensive good.

\qquad This is
done by a \darkblue{quantifier}, called \darkblue{$\sup$}.

\qquad \darkblue{$(\mathtt{Good} \to \mathtt{Price}) \to \mathtt{Price}$.}

\item[\grey{2.}]
Find the \darkblue{most expensive
good}.

\qquad This is done by a \darkblue{selection function}, called \darkblue{$\argsup$}.

\qquad \darkblue{$(\mathtt{Good} \to \mathtt{Price}) \to \mathtt{Good}$.}
\end{enumerate}

\overhead{Maximum-Value Theorem}

Any continuous function \darkblue{$p \colon [0,1] \to \R$} attains its
maximum value.

This means that there is \darkblue{$a \in [0,1]$} such that
\[
\darkblue{\sup p = p(a)}. 
\]

\vfill

However, the proof is non-constructive.

A maximizing argument \darkblue{$a$} cannot be algorithmically
calculated from
\darkblue{$p$}. % with an algorithm that works for all~\darkblue{$p$}.


\overhead{Mean-Value Theorem}

There is \darkblue{$a \in [0,1]$} such that
\[
\darkblue{\int p = p(a)}.
\]

\vfill

Again this \darkblue{$a$} cannot be found from \darkblue{$p$} using an algorithm. 

\overhead{Drinker Paradox}

Can be written as
\[
\darkblue{\forall(p) = p(a)}.
\]

Finding elements in sets corresponds to
\[
\darkblue{\exists(p) = p(a)}.
\]

\vfill

We can find \darkblue{$a$} as \darkblue{$a=\varepsilon(p)$} if the
ranges of the universal and existential quantifiers are \darkblue{finite}.

\darkblue{And we'll go beyond the finite case below.}

\overhead{General situation}

%The general equation we are considering here is thus

With $\phi$ among \darkblue{$\exists, \forall, \sup, \inf, \int, \dots$}, 
\[
\darkblue{\phi(p) = p(a)}.
\]

In favourable circumstances \darkblue{$a$} can be calculated as 
\[ \darkblue{a =\varepsilon(p)}.\] 

% \overhead{Haskell code}

% \begin{verbatim}
%  argsup :: J Int Bool
%  argsup p = p True > p False

%  sup :: K Int Bool
%  sup = overline argsup  
% \end{verbatim}
% Of course the definition of \verb+argsup+ is equivalent to
% \begin{verbatim}
%   argsup p = if p True > p False then True else False
% \end{verbatim}


\overhead{Haskell code}

%If we want our goods to be given as a list, we can instead define
\begin{verbatim}
 argsup, arginf :: [x] -> J Int x
 argsup [] p = undefined
 argsup [x] p = x
 argsup (x:y:zs) p = if p x < p y 
                     then argsup (y:zs) p 
                     else argsup (x:zs) p
\end{verbatim}
These will be useful for two-player games in which there
can be a draw.

%\overhead{Binary products of selection functions}
\overhead{Binary product of quantifiers and selection functions}

In every pub there are a man~\darkblue{$a_0$} and a
woman~\darkblue{$a_1$} such that if~\darkblue{$a_0$} buys a drink
to~\darkblue{$a_1$} then every man buys a drink to some woman.

\vfill

\overhead{Binary product of quantifiers and selection functions}

In every pub there are a man~\darkblue{$a_0$} and a
woman~\darkblue{$a_1$} such that if~\darkblue{$a_0$} buys a drink
to~\darkblue{$a_1$} then every man buys a drink to some woman.

\vfill


If \darkblue{$X_0 = \text{set of men}$} and \darkblue{$X_1 = \text{set
    of women}$}, and if we define % the combined quantifier
\darkblue{$\phi = \forall \otimes \exists$} by
\[
\darkblue{\phi(p) = \left(\forall x_0 \in X_0 \,\, \exists x_1 \in X_1 \,\, p(x_0,x_1)\right)},
\]
then this amounts to saying that
\[
\darkblue{\phi(p) = p(a)}
\]
for a suitable pair \darkblue{$a = (a_0,a_1) \in X_0 \times X_1$},

\vfill

Our objective is to calculate such a pair. %~\darkblue{$a$}.

\overhead{Binary product of quantifiers and selection functions}


We have selection functions
for~\darkblue{$\forall$} and~\darkblue{$\exists$}, say
\darkblue{$\varepsilon_0$} and \darkblue{$\varepsilon_1$}.

\vfill

We need a selection function
\darkblue{$\varepsilon = \varepsilon_0 \otimes \varepsilon_1$} for the
quantifier~\darkblue{$\phi = \forall \otimes \exists$}.

\overhead{Binary product of quantifiers}

It is easy to define the product \darkblue{$\otimes$} of quantifiers,
generalizing from the previous example, where \darkblue{$\phi = \phi_0 \otimes
  \phi_1$} for \darkblue{$\phi_0 = \forall$} and \darkblue{$\phi_1 =
  \exists$}:
\[
\darkblue{(\phi_0 \otimes \phi_1)(p)=\phi_0(\lambda x_0.\phi_1(\lambda x_1.p(x_0,x_1)))}.
\]

\overhead{Binary products of selection functions}

The definition of the product of selection functions is a bit subtler:
\begin{eqnarray*}
  \darkblue{(\varepsilon_0 \otimes \varepsilon_1)(p)} & \darkblue{=} & \darkblue{(a_0,a_1)} \\
        & \text{where} & \darkblue{a_0 = \varepsilon_0(\lambda x_0.\overline{\varepsilon_1}(\lambda x_1.p(x_0.x_1)))} \\
        & & \darkblue{a_1 = \varepsilon_1(\lambda x_1.p(a_0,x_1))}.
\end{eqnarray*}
We need to check that 
\[
\darkblue{\overline{\varepsilon_0} \otimes \overline{\varepsilon_1}
= \overline{\varepsilon_0 \otimes \varepsilon_1}},
\]
which amounts to
\begin{quote}
  if \darkblue{$\phi_0 = \overline{\varepsilon_1}$} and \darkblue{$\phi_1 =
  \overline{\varepsilon_1}$}, then \darkblue{$\phi_0 \otimes \phi_1 =
  \overline{\varepsilon_0 \otimes \varepsilon_1}$}.
\end{quote}


\overhead{Back to our motivating example}

The required man and woman can be calculated with the formula
\[
\darkblue{(a_0,a_1) = (\varepsilon_0 \otimes \varepsilon_1)(p)},
\]
where \darkblue{$\varepsilon_0$} and \darkblue{$\varepsilon_1$} are selection functions for
the quantifiers \darkblue{$\forall$} and~\darkblue{$\exists$} respectively.

\overhead{Iterated product}

Given a sequence of sets \darkblue{$X_0,X_1,\dots,X_{n},\dots$},
write
\[
\darkblue{\prod_{i<n} X_i = X_0 \times \cdots \times X_{n-1}}.
\]

\vfill

We define
$
\darkblue{\bigotimes \colon \prod_{i<n} J R X_i \to J R \prod_{i<n} X_i},
$
by induction on \darkblue{$n$}:
\[
  \darkblue{\bigotimes_{i < 0} \varepsilon_i  =  \lambda p.()}, \qquad
  \darkblue{\bigotimes_{i < n+1} \varepsilon_i   =  \varepsilon_0 \otimes \bigotimes_{i < n} \varepsilon_{i+1}}.
\]

\vfill

Informally, and assuming right associativity of \darkblue{$\otimes$}, 
\[
\darkblue{\bigotimes_{i < n} \varepsilon_i = \varepsilon_0 \otimes \varepsilon_1 \otimes \cdots \otimes \varepsilon_{n-1}}
\]
\overhead{Main property of products of selection functions}

Products of quantifiers can be defined in the same way, and 
%the following equation holds, by induction:
\[
\darkblue{\bigotimes_{i < n} \overline{\varepsilon_i} 
= \overline{\bigotimes_{i < n} \varepsilon_i}}.
\]

\vfill

The products are of quantifiers in the left-hand side and
of selection functions in the right-hand side.

\overhead{Haskell code}

\begin{verbatim}
 otimes :: J r x -> J r [x] -> J r [x]
 otimes e0 e1 p = a0:a1
  where a0 = e0(\x0 -> overline e1(\x1 -> p(x0:x1)))
        a1 = e1(\x1 -> p(a0:x1))

 bigotimes :: [J r x] -> J r [x]
 bigotimes [] = \p -> []
 bigotimes (e:es) = e `otimes` bigotimes es 
\end{verbatim}

\vfill

Although we have motivated this algorithm by considering finite lists, 
it does make sense for infinite lists too, as we shall see in due course.

\overhead{Playing games}

\vfill

\grey{1.}~Products of selection functions compute \darkblue{optimal
plays} and \darkblue{strategies}. 

\vfill

\grey{2.}~Generalize products in order to account for
\darkblue{history dependent} games.

~~~\,See proceedings for details. (I have the slides but not the time.)

\vfill

\grey{3.}~Give concise implementations of \darkblue{Tic-Tac-Toe} and
\darkblue{$n$-Queens} as illustrations.

\vfill

\overhead{First example}

\darkblue{Alternating, two-person game that finishes after exactly~$n$ moves.}

\vfill

\grey{1.}~\darkblue{Eloise} plays first, against
\darkblue{Abelard}. One of them wins (no draw).

\vfill

\grey{2.}~The \darkblue{$i$-th} move is an
element of the set \darkblue{$X_i$}.

\vfill

\grey{3.}~The game is defined by
a predicate \darkblue{$p \colon \prod_{i < n} X_i \to \mathtt{Bool}$}
\\ ~~~\,that tells whether Eloise wins
wins a given play \darkblue{$x = (x_0, \dots, x_{n-1})$}. 
% \in \prod_{i<n} X_i$}. 

\vfill

\grey{4.}~Eloise has a winning strategy for the
game \darkblue{$p$} if and only if
\[
\darkblue{\exists x_0 \!\in\! X_0 \forall x_1 \!\in\! X_1\exists x_{2} \!\in\! X_{2} \forall x_{3} \!\in\! X_{3} \cdots p(x_0, \ldots, x_{n-1})}.
\]

\overhead{First example}

\grey{4.}~Eloise has a winning strategy for the game \darkblue{$p$} if
and only if
\[
\darkblue{\exists x_0 \!\in\! X_0 \forall x_1 \!\in\! X_1\exists x_{2} \!\in\! X_{2} \forall x_{3} \!\in\! X_{3} \cdots p(x_0, \ldots, x_{n-1})}.
\]
If we define
\[
  \darkblue{\phi_i =  
  \begin{cases}
    \exists_{X_i} & \text{if $i$ is even,} \\
    \forall_{X_i} & \text{if $i$ is odd,} 
  \end{cases}}
\]
then this condition for Eloise
having a winning strategy can be equivalently expressed as
%
\[ \darkblue{\left(\bigotimes_{i<n} \phi_i\right)(p)}. \] 

\overhead{Calculating the optimal outcome of a game}

More generally,
the value
\[ \darkblue{\left(\bigotimes_{i<n} \phi_i\right)(p)} \]

gives the \darkblue{optimal outcome} of the game.

\vfill

This takes place
when all players play as best as they can.  

In the first example, the optimal outcome is
\darkblue{$\mathtt{True}$} if Eloise has a winning strategy, and
\darkblue{$\mathtt{False}$} if Abelard has a winning strategy.

\overhead{Calculating an optimal play}

Suppose each quantifier \darkblue{$\phi_i$} has a selection function
\darkblue{$\varepsilon_i$} (thought of as a policy function for the
\darkblue{$i$-th} move).

\vfill

\darkblue{Theorem.}
The sequence \[ \darkblue{a = (a_0,\dots,a_{n-1}) = \left(\bigotimes_{i < n}
    \varepsilon_i\right)(p)}\] is an \darkblue{optimal play}. 

\vfill

This means that for every stage \darkblue{$i<n$} of the game, the move
\darkblue{$a_i$} is optimal given that the moves
\darkblue{$a_0,\dots,a_{i-1}$} have been played.

\overhead{Finding an optimal strategy}

\darkblue{Theorem.}
The function \darkblue{$f_k : \prod_{i < k} X_i
\to X_k$} defined by %, for $k < n-1$,
        \[
        \darkblue{f_k(a) = \left(\left(\bigotimes_{i=k}^{n-1}
    \varepsilon_i\right)(\lambda x.p(a \concat x))\right)_0}
        \]
    is an \darkblue{optimal strategy} for playing the game. 

\vfill

This means that given that the sequence of moves
\darkblue{$a_0,\dots,a_{k-1}$} have been played, the move
\darkblue{$a_k=f_k(a_0,\dots,a_{k-1})$} is optimal.

\overhead{Second example}
    
Choose \darkblue{$R = \{-1,0,1\}$}
instead, with the convention that 
\[
\darkblue{\begin{cases}
 -1 = \text{Abelard wins,} & \\
 \phantom{-}0 = \text{draw}, & \\
 \phantom{-}1 = \text{Eloise wins.} & 
\end{cases}}
\]
The existential and universal quantifiers get
replaced by \darkblue{$\sup$} and \darkblue{$\inf$}:
\[
  \darkblue{\phi_i =  
  \begin{cases}
    \sup_{X_i} & \text{if $i$ is even,} \\
    \inf_{X_i} & \text{if $i$ is odd.} 
  \end{cases}}
\]
The optimal outcome is still calculated as \darkblue{$\bigotimes_{i<n}
  \phi_i$}, which %in this case 
amounts to
\[
\darkblue{\darkblue{\sup_{x_0 \!\in\! X_0} \inf_{x_1 \!\in\! X_1}\sup_{x_{2} \!\in\! X_{2}} \inf_{x_{3} \!\in\! X_{3}} \cdots p(x_0, \ldots, x_{n-1})}}.
\]

\overhead{Second example}

The \darkblue{optimal outcome} is 
\[
\darkblue{\begin{cases}
 -1 = \text{Abelard has a winning strategy,} & \\
 \phantom{-}0 = \text{the game is a draw}, & \\
 \phantom{-}1 = \text{Eloise has a winning strategy.} & 
\end{cases}}
\]

\vfill

Can compute optimal outcomes, plays and strategies with the same formulas.

\overhead{History-dependent games}

\vfill

Allowed moves in the next round depend on the moves played so far.

\vfill

The idea is that the $n$th selection function depends on the first $n$ played moves.

\vfill

It selects moves among the allowed ones, which depend on the played
ones.

\vfill

See the proceedings for mathematical details.




\overhead{Haskell code}

\vfill

\begin{verbatim}
otimes :: J r x -> (x -> J r [x]) -> J r [x]
otimes e0 e1 p = a0 : a1
 where a0 = e0(\x0->overline(e1 x0)(\x1->p(x0:x1)))
       a1 = e1 a0 (\x1 -> p(a0:x1))


bigotimes :: [[x] -> J r x] -> J r [x]
bigotimes [] = \p -> []
bigotimes (e:es) =  
 e[] `otimes` (\x->bigotimes[\xs->d(x:xs) | d<-es])
\end{verbatim}

\vfill


% The input for \verb+bigotimes+ is 
% \[
% \varepsilon = [\varepsilon_0, \varepsilon_1, \dots, \varepsilon_n, \dots],
% \]
% where the policy function $\varepsilon_n$ depends on first $n$ moves.



\overhead{Implementation of games}

We need to define a type \darkblue{$\mathtt{R}$} of outcomes, a type
\darkblue{$\mathtt{Move}$} of moves, a predicate
\begin{verbatim}
 p :: [Move] -> R
\end{verbatim}
that gives the outcome of a play, and (history-dependent)
\darkblue{selection functions} for each stage of the game:
\begin{verbatim}
 epsilons :: [[Move] -> J R Move] 
\end{verbatim}

\overhead{Implementation of games}

Each different game needs a different definition
\begin{quote}
  \verb+(R, Move, p, epsilons)+
\end{quote}

\overhead{Implementation of optimal plays}

But all games are played in the same way, using the previous theorems:
\begin{verbatim}
 optimalPlay :: [Move]
 optimalPlay = bigotimes epsilons p

 optimalOutcome :: R
 optimalOutcome = p optimalPlay

 optimalStrategy :: [Move] -> Move
 optimalStrategy as = head(bigotimes epsilons' p')
   where epsilons' = drop (length as) epsilons
         p' xs = p(as ++ xs)
\end{verbatim}

\overhead{Tic-Tac-Toe}

\newcommand{\play}[9]{\text{%
\begin{tabular}{c|c|c}
$#1$ & $#2$ & $#3$ \\ \hline
$#4$ & $#5$ & $#6$ \\ \hline
$#7$ & $#8$ & $#9$
\end{tabular}%
}%
}

\begin{verbatim}
 data Player = X | O
\end{verbatim}
The outcomes are $R = \{-1, 0, 1\}$.
\begin{verbatim}
 type R = Int
\end{verbatim}
The possible moves are
\[
\play{0}{1}{2}{3}{4}{5}{6}{7}{8}
\]
\begin{verbatim}
 type Move = Int 
\end{verbatim}
\begin{verbatim}
 type Board = ([Move], [Move])
\end{verbatim}

\overhead{Tic-Tac-Toe}
\begin{verbatim}
 wins :: [Move] -> Bool
 wins = 
  someContained [[0,1,2],[3,4,5],[6,7,8],
                 [0,3,6],[1,4,7],[2,5,8],
                 [0,4,8],[2,4,6]]

 value :: Board -> R
 value (x,o) | wins x    =  1 
             | wins o    = -1 
             | otherwise =  0
\end{verbatim}

\overhead{Tic-Tac-Toe}

\begin{verbatim}
 outcome :: Player -> [Move] -> Board -> Board

 outcome whoever [] board = board

 outcome X (m : ms) (x, o) = 
  if wins o then (x, o) 
  else outcome O ms (insert m x, o)

 outcome O (m : ms) (x, o) = 
  if wins x then (x, o) 
  else outcome X ms (x, insert m o)
\end{verbatim}

We assume that
player~\verb+X+ starts, as usual:
\begin{verbatim}
 p :: [Move] -> R
 p ms = value(outcome X ms ([],[]))
\end{verbatim}

\overhead{Tic-Tac-Toe}

\begin{verbatim}
 epsilons :: [[Move] -> J R Move]
 epsilons = take 9 epsilons
  where epsilons = epsilonX : epsilonO : epsilons
        epsilonX h = argsup ([0..8] `setMinus` h) 
        epsilonO h = arginf ([0..8] `setMinus` h) 
\end{verbatim}

\overhead{Let's run this}

\begin{verbatim}
 main :: IO ()
 main =  putStr 
 ("An optimal play for Tic-Tac-Toe is " ++ show optimalPlay ++ 
  "\nand the optimal outcome is " ++ show optimalOutcome ++ "\n")
\end{verbatim}
Compile and run:
\begin{verbatim}
 $ ghc --make -O2 TicTacToe.hs
 $ time ./TicTacToe
 An optimal play for Tic-Tac-Toe is [0,4,1,2,6,3,5,7,8]
 and the optimal outcome is 0

 real 0m1.721s    user 0m1.716s   sys 0m0.004s
\end{verbatim}
(Under the operating system Ubuntu/Debian 9.10 in a
2.13GHz machine.)

\overhead{In pictures}

\newcommand{\X}{\text{X}}
\renewcommand{\O}{\text{O}}
\newcommand{\n}{\phantom{\O}}
% [0,4,1,2,6,3,5,7,8]
%  x o x o x o x o x
\[
\begin{array}{ccc}
%     0    1   2   3   4   5   6   7   8
\play{\X}{\n}{\n}{\n}{\n}{\n}{\n}{\n}{\n} & \quad
\play{\X}{\n}{\n}{\n}{\O}{\n}{\n}{\n}{\n} & \quad
\play{\X}{\X}{\n}{\n}{\O}{\n}{\n}{\n}{\n} \\[7ex]

\play{\X}{\X}{\O}{\n}{\O}{\n}{\n}{\n}{\n} & \quad
\play{\X}{\X}{\O}{\n}{\O}{\n}{\X}{\n}{\n} & \quad
\play{\X}{\X}{\O}{\O}{\O}{\n}{\X}{\n}{\n} \\[7ex]

\play{\X}{\X}{\O}{\O}{\O}{\X}{\X}{\n}{\n} & \quad
\play{\X}{\X}{\O}{\O}{\O}{\X}{\X}{\O}{\n} & \quad
\play{\X}{\X}{\O}{\O}{\O}{\X}{\X}{\O}{\X}
\end{array}
\]

\overhead{$n$-Queens}

We adopt the following conventions:
\begin{enumerate}
\item[\grey{1.}] A solution is a permutation of
  \darkblue{$[0..(n-1)]$}, which tells where each queen should be
  placed in each row.
\item[\grey{1.}]  A move is an element of \darkblue{$[0..(n-1)]$},
  saying in which column of the given row (=stage of the game) the
  queen should be placed.
\end{enumerate}

\overhead{$n$-Queens}

\begin{verbatim}
 n = 8
 type R = Bool
 type Coordinate = Int
 type Move = Coordinate
 type Position = (Coordinate,Coordinate)

 attacks :: Position -> Position -> Bool
 attacks (x, y) (a, b) = 
   x == a  ||  y == b  || abs(x - a) == abs(y - b)

 valid :: [Position] -> Bool
 valid [] = True
 valid (u : vs) =  
   not(any (\v -> attacks u v) vs) && valid vs
\end{verbatim}
\overhead{$n$-Queens}
\begin{verbatim}
 p :: [Move] -> R
 p ms = valid(zip ms [0..(n-1)])

 epsilons :: [[Move] -> J R Move]
 epsilons = replicate n epsilon
  where epsilon h = find ([0..(n-1)] `setMinus` h)
\end{verbatim}
\overhead{$n$-Queens}

\begin{verbatim}
 main :: IO ()
 main = putStr 
  ("An optimal play for " ++ show n ++  "-Queens is " ++ 
                                         show optimalPlay ++
   "\nand the optimal outcome is " ++ show optimalOutcome ++ "\n")
\end{verbatim}
Compile and run:
\begin{verbatim}
 $ ghci --make -O2 NQueens.hs
 $ time ./NQueens 
\end{verbatim}
and we get:
\begin{verbatim}
 An optimal play for 8-Queens is [0,4,7,5,2,6,1,3]
 and the optimal outcome is True

 real 0m0.011s   user 0m0.012s    sys 0m0.000s
\end{verbatim}

\overhead{12-Queens}

Get $[0,2,4,7,9,11,5,10,1,6,8,3]$  computed in five
seconds.  

\overhead{The Tychonoff Theorem}

\vfill

\grey{1.} Close connection of some computational and
topological ideas.

\vfill

\grey{2.} With applications to computation.  

\vfill

\grey{3.} No background on topology required.

\vfill

\overhead{The language spoken in Topology Land}

Space.

Continuous function.

Compact space.

Countably based space.

Hausdorff space.

Cantor space.

Baire space.

\overhead{Guided tour to Topology Land}

Call a set
\begin{enumerate}
\item \darkblue{searchable} if it has a computable selection function, and
\item \darkblue{exhaustible} if it has a computable boolean-valued quantifier.
\end{enumerate}
We showed that
\begin{quote}
  \darkblue{Exhaustible and searchable sets are compact.}
\end{quote}


Related to the well-known fact that
\begin{quote}
\darkblue{Computable functionals are continuous.}

Finite parts of the output depend only on finite parts of the input. 
\end{quote}


\overhead{A widely quoted topological slogan}
\begin{quote}
  \darkblue{Infinite compact sets behave, in many interesting and useful
    ways, as if they were finite.}
\end{quote}

\vfill

This matches computational intuition:

\begin{quote}
The ability to
exhaustively search an infinite set, algorithmically and in finite
time, is indeed a computational sense in which the set behaves as if
it were finite. 
\end{quote}

\vfill

It may seem surprising at first sight that there are
such sets, but this was known in the 1950's or
before.

\overhead{Topological properties}

\begin{quote}
  \darkblue{Compact sets of total elements form countably based Hausdorff spaces.}
\end{quote}

\overhead{Importing results from topology to computation}

We had previously explored what happens if one looks at theorems in
topology and applies the previous dictionary.

  \darkblue{Exhaustible and searchable sets are compact.}

  \darkblue{Computable functions are continuous.}

  \darkblue{Searchable sets of total elements form countably based Hausdorff spaces.}

\overhead{Some results in topology}

\begin{enumerate}
\item[\grey{1.}] Finite sets are compact, and hence for example the booleans are compact.

\item[\grey{2.}] Arbitrary products of compact sets are compact (Tychonoff
  Theorem). 

  Hence the space of infinite sequences of booleans is compact. 

  This the \emph{Cantor space}.
%   , as it is topologically
%   isomorphic (or homeomorphic) to the famous Cantor Third-Middle set
%   in the real line.

\item[\grey{2.}] Continuous images of compact sets are compact.

\item[\grey{3.}] Any non-empty, countably based, compact Hausdorff space
is a continuous image of the Cantor space. 
\end{enumerate}

\overhead{Applying the dictionary, we get}
\begin{enumerate}
\item[\grey{1.}] \label{cs:land:1} Finite sets are searchable, and hence for example the booleans are searchable.
\item[\grey{2.}] \label{cs:land:2}Finite and countably infinite products of searchable sets are
  searchable.

  Hence the Cantor space is searchable. 

\item[\grey{3.}] \label{cs:land:3} Computable images of searchable/exhaustible sets are  searchable/exhaustible.
\item[\grey{4.}] \label{cs:land:4} Any non-empty exhaustible set is a computable
  image of the Cantor space.
\end{enumerate}

\overhead{A souvenir from our excursion}

\begin{quote}
  \darkblue{Non-empty exhaustible sets are searchable.}
\end{quote}

This is computationally interesting:
\begin{quote}
  If we have a search procedure that answers \darkblue{yes/no}
  \grey{(given by a quantifier)},

  we get a procedure that gives \darkblue{witnesses} \grey{(given by a
    selection function)}.
\end{quote}

\overhead{Haskell code}

The Tychonoff Theorem is
implemented by the history-free version \verb+bigotimes+ of the
product of selection functions. 

\vfill

Hence a selection function for the
Cantor space is given by
\begin{verbatim}
 findCantor :: J Bool [Bool]
 findCantor = bigotimes (repeat findBool)
\end{verbatim}

\overhead{Haskell code}

Computable images of searchable sets are searchable:
\begin{verbatim}
 image :: (x -> y) -> J r x -> J r y
 image f e = \q -> f(e(\x -> q(f x)))
\end{verbatim}

\overhead{Application: deciding equality of functionals}

Perhaps contradicting common wisdom, we write a
total (!) functional that decides whether or not two given total
functionals equivalent:

\vfill

\begin{verbatim}
 equal :: Eq z => ((Integer -> Bool) -> z) 
               -> ((Integer -> Bool) -> z) -> Bool 

 equal f g = foreveryFunction(\u->f u == g u)
\end{verbatim}

\vfill

This doesn't contradict computability theory.


\overhead{Haskell code} Code functions \verb+Integers->Bool+ as lazy
lists by storing \darkblue{non-negative} and \darkgreen{negative}
arguments at \darkblue{even} and \darkgreen{odd} indices:

\vfill

\begin{verbatim}
 code :: (Integer -> Bool) -> [Bool]
 code f = [f(reindex i)| i<-[0..]]
   where reindex i | even i    =      i `div` 2
                   | otherwise = -((i+1)`div` 2)
\end{verbatim}

\overhead{Haskell code}
But actually we are interested in the opposite direction:
\begin{verbatim}
 decode :: [Bool] -> (Integer -> Bool)
 decode xs i | i >= 0    =  xs `at`   (i * 2)
             | otherwise =  xs `at` ((-i * 2) - 1)

 at :: [x] -> Integer -> x
 at (x:xs) 0 = x
 at (x:xs) (n+1) = at xs n
\end{verbatim}


\overhead{Haskell code}

\begin{verbatim}
 findFunction :: J Bool (Integer -> Bool)
 findFunction = image decode findCantor

 forsomeFunction :: K Bool (Integer -> Bool)
 forsomeFunction = overline findFunction

 foreveryFunction :: K Bool (Integer -> Bool)
 foreveryFunction p = not(forsomeFunction(not.p))
\end{verbatim}

~

This completes the definition of the function \verb+equal+.

\overhead{Experiment}
Here the function \verb+c+ is a coercion:
\begin{verbatim}
 c :: Bool -> Integer
 c False = 0
 c True  = 1

 f, g, h :: (Integer -> Bool) -> Integer
 f a = c(a(7 * c(a 4) +  4 * (c(a 7)) + 4))
 g a = c(a(7 * c(a 5) +  4 * (c(a 7)) + 4))
 h a = if not(a 7)
       then if not(a 4) then c(a  4) else c(a 11)
       else if a 4      then c(a 15) else c(a  8)
\end{verbatim}
\darkblue{Are any two of these three functions equal?}

\overhead{Experiment}
When we run this, using the
interpreter this time, we get:
\begin{verbatim}
 $ ghci Tychonoff.hs
 ...
 Ok, modules loaded: Main.
*Main> :set +s
*Main> equal f g
False
(0.02 secs, 4274912 bytes)
*Main> equal g h
False
(0.01 secs, 0 bytes)
*Main> equal f h
True
(0.00 secs, 0 bytes)
\end{verbatim}


\overhead{Experiment}
Where do \verb+f+ and \verb+g+
differ?

\vfill

\begin{verbatim}
*Main> take 11 (code (findFunction(\u->g u /= h u))) 
[True,True,True,True,True,True,True,True,True,True,False]
(0.05 secs, 3887756 bytes)
\end{verbatim}

\vfill

\darkblue{We believe that these ideas open up the possibility of new,
  useful tools for automatic program verification and bug finding.}



\overhead{Monads}

It turns out that the function \verb+image :: (x -> y) -> J r x -> J r y+
defined above is the functor of a monad.  

\vfill

The unit is
\begin{verbatim}
 singleton :: x -> J r x
 singleton x = \p -> x
\end{verbatim}
%It implements the fact that singletons are searchable.

\vfill

The multiplication is
\begin{verbatim}
 bigunion :: J r (J r x) -> J r x
 bigunion e = \p -> e(\d -> overline d p) p
\end{verbatim}
%It implements the fact that a the union of a searchable set of
%searchable sets is searchable.


\overhead{Haskell code for the monads}

See the proceedings.

\overhead{Consequences of having a monad}

The history-free version of the functional \verb+bigotimes+ is simply
the Haskell \darkblue{standard prelude} function \verb+sequence+
instantiated to the selection monad:
\begin{verbatim}
 sequence :: Monad m => [m a] -> m [a] 
 sequence = foldr mcons (return [])
             where mcons p q = 
                    p >>= \x->q >>= \y->return (x:y)
\end{verbatim}

\vfill

Thus, our computational manifestation of the Tychonoff Theorem is
already in the Haskell standard prelude, and becomes immediately
available once one defines the selection monad.

\overhead{The history-dependent product}

Can also be defined for any monad. See the paper.


\overhead{The Double-Negation Shift} 

\darkblue{$\forall n \,\, \neg \neg (A n) \implies \neg \neg \forall n
  \,\, (A n)$}.

\vfill


Used by Spector'62 to realize the \darkblue{Classical Axiom of Countable
  Choice}.



\qquad He used the \darkblue{dialectica interpretation}.

\qquad We use Kreisel's \darkblue{modified realizability}.

\overhead{$K$-shift}

Generalized double negation shift.

\vfill

Monad \darkblue{$K A = (A \to R) \to R$}.

\vfill

\darkblue{$\forall x \, K (A x) \implies K \forall x \,\, (A x)$}.

\vfill

Algebra \darkblue{$K A \to A$}: proposition \darkblue{$A$} with
double-negation elimination.

\vfill

CPS-translation = G\"odel--Gentzen negative translation.

\overhead{$J$-shift}

Gives the double negation shift via the monad morphism \darkblue{$J \to K$}.

\vfill

Monad \darkblue{$J A = (A \to R) \to A$}.

\vfill

\darkblue{$\forall x \, J (A x) \implies J \forall x \,\, (A x)$}
directly realized by \darkblue{$\bigotimes$}.

\vfill

Algebra \darkblue{$J A \to A$}: proposition \darkblue{$A$} that
satisfies Peirce's Law.

\vfill

Get translation based on \darkblue{$J$} rather than \darkblue{$K$}.

\vfill

Get witnesses from classical proofs that use countable choice using
\darkblue{$\bigotimes$}. 

\overhead{Concluding remarks}

Diverse mathematical subjects coexist harmoniously
and have a natural bed in functional programming: 
\begin{enumerate}
\item[\grey{1.}] 
game theory (optimal
strategies), 
\item[\grey{2.}]  topology (Tychonoff Theorem), 
\item[\grey{3.}]  category theory (monads),
and 
\item[\grey{4.}]  proof theory (double-negation shift, classical axiom
  of choice).
\end{enumerate}

\overhead{Selection functions everywhere} 

It is the \darkblue{selection monad} that unifies these
mathematical subjects. 

\vfill

Its associated product
functional~\darkblue{$\bigotimes$}
\begin{enumerate}
\item[\grey{1.}]  
computes optimal strategies, 
\item[\grey{2.}]  implements a
computational manifestation of the Tychonoff Theorem, 
\item[\grey{3.}]  realizes the
double-negation shift and the classical axiom of choice. 
\end{enumerate}

\overhead{Thanks!}

\end{document}
